{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "import numpy as np\n",
        "import math\n",
        "import torchvision\n",
        "import re"
      ],
      "metadata": {
        "id": "ld6OrnLmD6JM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr --quiet\n",
        "import easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAk_QERsrsCN",
        "outputId": "0ba10aa3-37d3-4ad5-b88a-352c39e7f5f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.2/619.2 KB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6E73YkDze1",
        "outputId": "e37baa53-d3e9-439a-e364-c90f3b3fdb2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1127, done.\u001b[K\n",
            "remote: Total 1127 (delta 0), reused 0 (delta 0), pack-reused 1127\u001b[K\n",
            "Receiving objects: 100% (1127/1127), 69.93 MiB | 24.77 MiB/s, done.\n",
            "Resolving deltas: 100% (522/522), done.\n",
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.experimental import attempt_load\n",
        "from utils.general import check_img_size, non_max_suppression, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.torch_utils import time_synchronized\n",
        "from utils.datasets import letterbox"
      ],
      "metadata": {
        "id": "EB5rOfT3EFVk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(model, source):\n",
        "\n",
        "    device = 'cpu'\n",
        "    imgsz = 640\n",
        "    img = source\n",
        "\n",
        "\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check img_size TODO\n",
        "\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names\n",
        "    old_img_w = old_img_h = imgsz\n",
        "    old_img_b = 1\n",
        "    im0 = img\n",
        "\n",
        "        # Convert\n",
        "    img = letterbox(img, imgsz, stride=stride)[0]\n",
        "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "    img = np.ascontiguousarray(img)\n",
        "\n",
        "\n",
        "    img = torch.from_numpy(img).to(device)\n",
        "    img = img.float()  # uint8 to fp16/32\n",
        "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "    if img.ndimension() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
        "        pred = model(img)[0]\n",
        "    # Apply NMS\n",
        "    pred = non_max_suppression(pred, 0.25, 0.45, classes=[0,1,2,3,4,5])\n",
        "\n",
        "    # Process detections\n",
        "    outputs = []\n",
        "    for i, det in enumerate(pred):  # detections per image\n",
        "\n",
        "        if len(det):\n",
        "\n",
        "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "            for *xyxy, conf, cls in reversed(det):\n",
        "                label = f'{names[int(cls)]}'\n",
        "                out = [t.item() for t in xyxy]\n",
        "                outputs.append((out, label, conf.item()))\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def crop_image(out, img):\n",
        "  x1 = int(out[0][0])\n",
        "  x2 = int(out[0][2])\n",
        "  y1 = int(out[0][1])\n",
        "  y2 = int(out[0][3])\n",
        "  # Cropping an image\n",
        "  cropped_image = img[y1:y2, x1:x2]\n",
        "\n",
        "  return cropped_image"
      ],
      "metadata": {
        "id": "3NVBc2GaEGCt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet\n",
        "!gdown 1qXBtVeOpZjeY-AduqtyTtu22y6RytGeO\n",
        "!gdown 1Ni_w3QCucfHI271ASUjk7k04GZseGJcz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7JV1tBFr1VK",
        "outputId": "19622b44-df37-40ab-a0b5-48c915872978"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qXBtVeOpZjeY-AduqtyTtu22y6RytGeO\n",
            "To: /content/yolov7/classify.pt\n",
            "100% 74.8M/74.8M [00:00<00:00, 99.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ni_w3QCucfHI271ASUjk7k04GZseGJcz\n",
            "To: /content/yolov7/segmentation.pt\n",
            "100% 74.8M/74.8M [00:01<00:00, 56.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = attempt_load('segmentation.pt')\n",
        "model2 = attempt_load('classify.pt')\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy9dZv8LGVWV",
        "outputId": "f7bdf081-c348-47c1-cb66-914dcc88c1f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4y9pzjtoawdV"
      },
      "outputs": [],
      "source": [
        "def inference(image_path:str):\n",
        "  '''\n",
        "  Function responsible for inference.\n",
        "  Args: \n",
        "    image_path: str, path to image file. eg. \"input/aveksha_micu_mon--209_2023_1_17_12_0_34.jpeg\"\n",
        "  Returns:\n",
        "    result: dict, final output dictionary. eg. {\"HR\":\"80\", \"SPO2\":\"98\", \"RR\":\"15\", \"SBP\":\"126\", \"DBP\":\"86\"}\n",
        "  '''\n",
        "  result = {}\n",
        "  img = cv2.imread(image_path)\n",
        "  \n",
        "  out1 = detect(model1, img)\n",
        "  out1_img = crop_image(out1[0], img)\n",
        "\n",
        "  out2 = detect(model2, out1_img)\n",
        "  temp = {}\n",
        "  \n",
        "  for out in out2:\n",
        "    out2_img = crop_image(out, out1_img)\n",
        "\n",
        "    r = reader.readtext(out2_img)\n",
        "    if(not r):\n",
        "      continue\n",
        "    r = r[0]\n",
        "\n",
        "    if(r[2] < 0.2):\n",
        "      continue\n",
        "\n",
        "    tt = temp.get(out[1])\n",
        "    if(tt):\n",
        "      if tt['class_conf'] > out[2]:\n",
        "        continue\n",
        "\n",
        "\n",
        "    temp[out[1]] = {\n",
        "          'class_conf': out[2],\n",
        "          'value': re.sub(\"[^0-9]\", \"\", r[1]),\n",
        "          'value_conf': r[2]\n",
        "      }\n",
        "\n",
        "  l = ['HR', 'SPO2', 'RR', 'SBP', 'DBP', 'MAP']\n",
        "\n",
        "  for i in l:\n",
        "    if(not temp.get(i)):\n",
        "      continue\n",
        "\n",
        "    result[i] = temp[i]['value']\n",
        "\n",
        "  return result"
      ]
    }
  ]
}